# Машиное обучение текстов "Проект по поиску токсичных комментариев"
Интернет-магазин «Викишоп» запускает новый сервис, чтобы пользователи могли редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину запросил инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Цель проекта: обучить модель классифицировать комментарии на позитивные и негативные.

Задачи:
1.	Обработать данные
2.	Обучить разные модели
3.	Построить модель со значением метрики качества F1 не меньше 0.75.

Навыки и инструменты: Python, Pandas, BERT, NLP, машинное обучение, tf-idf, nltk

Выводы:

Поскольку из-за объема данных у меня умирало ядро, то я сделала проект на части данных.

Была произведена токенизация, лемматизация текста в датасете. Также были убраны стопслова и произведена векторизация. После векторизации были обучены 4 модели c кроссвалидацией и подбором гиперпараметров: LogisticRegression(), DecisionTreeClassifier(), CatBoostClassifier(), SGDClassifier() Наилучшие результаты по параметру F1 у LogisticRegression() и SGDClassifier(), а у SGDClassifier() при предсказании по параметру F1 показала наилучший результат (0.771134 для сэмпла данных 15000). А для сэмпла данных из 50000, лучший результат у LogisticRegression() - 0.7606. Для сэмпла данных из 100000, лучший результат также у LogisticRegression() 0.763626 и при обучении с паплайном результат чуть выше: 0.766273

